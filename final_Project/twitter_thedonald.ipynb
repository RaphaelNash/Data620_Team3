{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter\n",
    "\n",
    "## Kelly Shaffer, Raphael Nash, Xiaomeng (Vivian) Kong, Michael Muller, Blandon Casenave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import sys\n",
    "import os\n",
    "from networkx.algorithms import bipartite as bi\n",
    "#twitter OAUTH \n",
    "import time as tm\n",
    "import json\n",
    "import argparse as ag\n",
    "import tweepy as tw\n",
    "from tweepy.streaming import StreamListener as sl\n",
    "from tweepy import OAuthHandler as oa\n",
    "from tweepy import Stream as st\n",
    "import oauth2 as oauth\n",
    "import re\n",
    "import dateutil.parser as dp\n",
    "from pytz import timezone as tz\n",
    "import pytz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @NYCTSubway: Following an earlier Con Edison manhole fire at 34 St-Penn Station, 1, 2 and 3 train service has resumed with delays.\n",
      "RT @NYCTSubway: Our crews delivering portable generator to scene of Con Ed manhole fire near Penn Station Generator to supply AC power to n…\n",
      "RT @NYCTSubway: Updated information about the delays on the 1, 2, and 3 lines: https://t.co/q6hF5pSRzI\n",
      "Alternative routes to 1/2/3 subway are A/C/E or connection from Broadway 34/Herald Square B/D/F/M/N/Q/R/W\n",
      "There are currently delays in both directions on the 1/2/3 subway lines due to a ConEd manhole fire. Take alternative routes if possible.\n",
      "RT @NYCTSubway: b/d 1, 2 and 3 service changes and delays, due to a Con Ed manhole fire near 34 St-Penn Station. See https://t.co/vhZQ2kZ2vb\n",
      "LIRR Customers: Amtrak’s summer repairs at Penn start today, 7/10. For info on how this may impact your commute: https://t.co/QIhoXmCSBI\n",
      "Chief Development Officer Janno Lieber details technical limitations of the current subway signal system, &amp; how it… https://t.co/LeRgrqae7L\n",
      "Chairman Joe Lhota: \"The men and women who work at the MTA are some of the most dedicated, driven, and talented peo… https://t.co/e4C8T2t9XF\n",
      "Transit officials from Canada, France, Japan &amp; Switzerland are presenting about best practices at MTA Genius Transi… https://t.co/dQ9TFVrFFl\n",
      "Chair Lhota: \"New Yorkers deserve a safe, reliable and viable subway system. That is our goal. That is our charge.… https://t.co/GVAbjKg9UC\n",
      "RT @BethDeFalco: .@MTA Chairman Joe Lhota: \"We are going to think outside the box, live outside the box\" on ways to fix the subway.\n",
      "MTA Chair Lhota: \"The subway system was &amp; can be the crown jewel of the City of New York... I am under no illusions… https://t.co/Ss3ogpGrBS\n",
      "RT @BethDeFalco: .@MTA Chairman Joe Lhota: \"We don't have riders. We have customers. And our customers are always right.\"\n",
      "RT @GannettAlbany: “Change and improvement must come. And it must come now,” Cuomo says about @MTA as he pushes ‘transit challenge’ competi…\n",
      "The MTA Genius Transit Challenge is about to kick off. Watch live:  \n",
      "https://t.co/w9cntOw3Si\n",
      "RT @NYCTSubway: Following overnight emergency repair work at 125 St, A and D express service resumed.\n",
      "RT @NYCTSubway: Following overnight emergency repair work at 125 St, B and C local service resumed.\n",
      "RT @NYCTSubway: Following earlier emergency repair work at 125 St, A, B, C and D train service has resumed with extensive delays.\n",
      "RT @NYCTSubway: See below updated - the latest service changes in effect along the A and C lines. https://t.co/u3qaIVD4Lv\n"
     ]
    }
   ],
   "source": [
    "CONSUMER_KEY = \"vVgMvZu4a5UFuNNmIqLG6kdst\"\n",
    "CONSUMER_SECRET = \"SjEZQJIcMjSyP6Tj2blyJsrqfmtsHZmIaJldT0hlbpW4NNx2a3\"\n",
    "ACCESS_KEY = \"199763323-wPFrK2QTS9HiMyOnY2yfS1CCCQEGBaS0ZTG0YpfJ\"\n",
    "ACCESS_SECRET = \"CPowEv0tAn5Hka5ayCjlGcYl2kecvTJwqiQuSa0OYuF4m\"\n",
    "\n",
    "consumer = oauth.Consumer(key=CONSUMER_KEY, secret=CONSUMER_SECRET)\n",
    "access_token = oauth.Token(key=ACCESS_KEY, secret=ACCESS_SECRET)\n",
    "client = oauth.Client(consumer, access_token)\n",
    "\n",
    "timeline_endpoint = \"https://api.twitter.com/1.1/statuses/home_timeline.json\"\n",
    "response, data = client.request(timeline_endpoint)\n",
    "\n",
    "tweets = json.loads(data)\n",
    "for tweet in tweets:\n",
    "    print tweet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAUTH_KEYS = {'consumer_key':CONSUMER_KEY, 'consumer_secret':CONSUMER_SECRET,\n",
    " 'access_token_key':ACCESS_KEY, 'access_token_secret':ACCESS_SECRET}\n",
    "auth = tw.OAuthHandler(OAUTH_KEYS['consumer_key'], OAUTH_KEYS['consumer_secret'])\n",
    "api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = tw.Cursor(api.search, q='#donaldtrump').items(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn = []\n",
    "text = []\n",
    "timestamp =[]\n",
    "for tweet in search:\n",
    "    #print tweet.user.screen_name, tweet.created_at, tweet.text\n",
    "    timestamp.append(tweet.created_at)\n",
    "    sn.append(tweet.user.screen_name)\n",
    "    text.append(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert lists to dataframe\n",
    "df = pd.DataFrame()\n",
    "df['timestamp'] = timestamp\n",
    "df['sn'] = sn\n",
    "df['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare ford date filtering. Adding an EST time column since chat hosted by people in that time zone.\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['EST'] = df['timestamp'] - pd.Timedelta(hours=5) #Convert to EST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['EST'] = pd.to_datetime(df['EST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset for the dates required. Can select a specific date or time to examine.\n",
    "import time\n",
    "df = df[(pd.to_datetime(\"2015-12-14 20:00:00\", format='%Y-%m-%d %H:%M:%S') < df['EST']) & (df['EST'] < pd.to_datetime(\"2015-12-14 21:00:00\", format='%Y-%m-%d %H:%M:%S'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out Tweets in case they are needed later.\n",
    "df.to_csv('edtechtweets.csv',index = False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of the unique usernames in order to see which users we need to retrieve friends for.\n",
    "allNames = list(df['sn'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize dataframe of users that will hold the edge relationships\n",
    "dfUsers = pd.DataFrame()\n",
    "dfUsers['userFromName'] =[]\n",
    "dfUsers['userFromId'] =[]\n",
    "dfUsers['userToId'] = []\n",
    "count = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameCount = len(allNames)\n",
    "# The choice to retrieve friends (who the user is following) rather than followers is intentional.\n",
    "# Either would work. However, many Twitter users follow fewer users than are following them, especially the most popular accounts. \n",
    "# This reduces the number of very large calls to Twitter API, which seemed to cause problems.\n",
    "for name in allNames:\n",
    "    # Build list of friends    \n",
    "    currentFriends = []\n",
    "    for page in tweepy.Cursor(api.friends_ids, screen_name=name).pages():\n",
    "        currentFriends.extend(page)\n",
    "    currentId = api.get_user(screen_name=name).id\n",
    "    currentId = [currentId] * len(currentFriends)\n",
    "    currentName = [name] * len(currentFriends)   \n",
    "    dfTemp = pd.DataFrame()\n",
    "    dfTemp['userFromName'] = currentName\n",
    "    dfTemp['userFromId'] = currentId\n",
    "    dfTemp['userToId'] = currentFriends\n",
    "    dfUsers = pd.concat([dfUsers,dfTemp])\n",
    "    time.sleep(70) # avoids hitting Twitter rate limit\n",
    "    # Progress bar to track approximate progress\n",
    "    count +=1\n",
    "    per = round(count*100.0/nameCount,1)\n",
    "    sys.stdout.write(\"\\rTwitter call %s%% complete.\" % per)\n",
    "    sys.stdout.flush() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again, to limit the number of calls to Twitter API, just do lookups on followers that connect to those in our user group.\n",
    "# We are not interested in \"friends\" that are not part of this community.\n",
    "fromId = dfUsers['userFromId'].unique()\n",
    "dfChat = dfUsers[dfUsers['userToId'].apply(lambda x: x in fromId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['userFromName' 'userFromId'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1b02a07d4f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# No more Twitter API lookups are necessary. Create a lookup table that we will use to get the verify the userToName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfLookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfChat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userFromName'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'userFromId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfLookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfLookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfLookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'userToName'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'userToId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdfCommunity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfCommunity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfLookup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'userToId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/digitalmarketer1977/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/digitalmarketer1977/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/digitalmarketer1977/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['userFromName' 'userFromId'] not in index\""
     ]
    }
   ],
   "source": [
    "# No more Twitter API lookups are necessary. Create a lookup table that we will use to get the verify the userToName\n",
    "dfLookup = dfChat[['userFromName','userFromId']]\n",
    "dfLookup = dfLookup.drop_duplicates()\n",
    "dfLookup.columns = ['userToName','userToId']\n",
    "dfCommunity = dfCommunity.merge(dfLookup, on='userToId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'makedir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75caad94c42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLLOWING_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLLOWING_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'makedir'"
     ]
    }
   ],
   "source": [
    "FOLLOWING_DIR = 'following'\n",
    "MAX_FRIENDS = 200\n",
    "FRIENDS_OF_FRIENDS_LIMIT = 200\n",
    "\n",
    "if not os.path.exists(FOLLOWING_DIR):\n",
    "    os.makedir(FOLLOWING_DIR)\n",
    "\n",
    "enc = lambda x: x.encode('ascii', errors='ignore')\n",
    "\n",
    "# The consumer keys can be found on your application's Details\n",
    "# page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "CONSUMER_KEY = 'vVgMvZu4a5UFuNNmIqLG6kdst'\n",
    "CONSUMER_SECRET = 'SjEZQJIcMjSyP6Tj2blyJsrqfmtsHZmIaJldT0hlbpW4NNx2a3'\n",
    "\n",
    "# The access tokens can be found on your applications's Details\n",
    "# page located at https://dev.twitter.com/apps (located\n",
    "# under \"Your access token\")\n",
    "ACCESS_TOKEN = '199763323-wPFrK2QTS9HiMyOnY2yfS1CCCQEGBaS0ZTG0YpfJ'\n",
    "ACCESS_TOKEN_SECRET = 'CPowEv0tAn5Hka5ayCjlGcYl2kecvTJwqiQuSa0OYuF4m'\n",
    "\n",
    "# == OAuth Authentication ==\n",
    "#\n",
    "# This mode of authentication is the new preferred way\n",
    "# of authenticating with Twitter.\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "def get_follower_ids(centre, max_depth=1, current_depth=0, taboo_list=[]):\n",
    "\n",
    "    # print 'current depth: %d, max depth: %d' % (current_depth, max_depth)\n",
    "    # print 'taboo list: ', ','.join([ str(i) for i in taboo_list ])\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        print 'out of depth'\n",
    "        return taboo_list\n",
    "\n",
    "    if centre in taboo_list:\n",
    "        # we've been here before\n",
    "        print 'Already been here.'\n",
    "        return taboo_list\n",
    "    else:\n",
    "        taboo_list.append(centre)\n",
    "\n",
    "    try:\n",
    "        userfname = os.path.join('twitter-users', str(centre) + '.json')\n",
    "        if not os.path.exists(userfname):\n",
    "            print 'Retrieving user details for twitter id %s' % str(centre)\n",
    "            while True:\n",
    "                try:\n",
    "                    user = api.get_user(centre)\n",
    "\n",
    "                    d = {'name': user.name,\n",
    "                         'screen_name': user.screen_name,\n",
    "                         'id': user.id,\n",
    "                         'friends_count': user.friends_count,\n",
    "                         'followers_count': user.followers_count,\n",
    "                         'followers_ids': user.followers_ids()}\n",
    "\n",
    "                    with open(userfname, 'w') as outf:\n",
    "                        outf.write(json.dumps(d, indent=1))\n",
    "\n",
    "                    user = d\n",
    "                    break\n",
    "                except tweepy.TweepError, error:\n",
    "                    print type(error)\n",
    "\n",
    "                    if str(error) == 'Not authorized.':\n",
    "                        print 'Can''t access user data - not authorized.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    if str(error) == 'User has been suspended.':\n",
    "                        print 'User suspended.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    errorObj = error[0][0]\n",
    "\n",
    "                    print errorObj\n",
    "\n",
    "                    if errorObj['message'] == 'Rate limit exceeded':\n",
    "                        print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                        time.sleep(15 * 60 + 15)\n",
    "                        continue\n",
    "\n",
    "                    return taboo_list\n",
    "        else:\n",
    "            user = json.loads(file(userfname).read())\n",
    "\n",
    "        screen_name = enc(user['screen_name'])\n",
    "        fname = os.path.join(FOLLOWING_DIR, screen_name + '.csv')\n",
    "        friendids = []\n",
    "\n",
    "        # only retrieve friends of TED... screen names\n",
    "        if screen_name.startswith('TED'):\n",
    "            if not os.path.exists(fname):\n",
    "                print 'No cached data for screen name \"%s\"' % screen_name\n",
    "                with open(fname, 'w') as outf:\n",
    "                    params = (enc(user['name']), screen_name)\n",
    "                    print 'Retrieving friends for user \"%s\" (%s)' % params\n",
    "\n",
    "                    # page over friends\n",
    "                    c = tweepy.Cursor(api.friends, id=user['id']).items()\n",
    "\n",
    "                    friend_count = 0\n",
    "                    while True:\n",
    "                        try:\n",
    "                            friend = c.next()\n",
    "                            friendids.append(friend.id)\n",
    "                            params = (friend.id, enc(friend.screen_name), enc(friend.name))\n",
    "                            outf.write('%s\\t%s\\t%s\\n' % params)\n",
    "                            friend_count += 1\n",
    "                            if friend_count >= MAX_FRIENDS:\n",
    "                                print 'Reached max no. of friends for \"%s\".' % friend.screen_name\n",
    "                                break\n",
    "                        except tweepy.TweepError:\n",
    "                            # hit rate limit, sleep for 15 minutes\n",
    "                            print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                            time.sleep(15 * 60 + 15)\n",
    "                            continue\n",
    "                        except StopIteration:\n",
    "                            break\n",
    "            else:\n",
    "                friendids = [int(line.strip().split('\\t')[0]) for line in file(fname)]\n",
    "\n",
    "            print 'Found %d friends for %s' % (len(friendids), screen_name)\n",
    "\n",
    "            # get friends of friends\n",
    "            cd = current_depth\n",
    "            if cd+1 < max_depth:\n",
    "                for fid in friendids[:FRIENDS_OF_FRIENDS_LIMIT]:\n",
    "                    taboo_list = get_follower_ids(fid, max_depth=max_depth,\n",
    "                        current_depth=cd+1, taboo_list=taboo_list)\n",
    "\n",
    "            if cd+1 < max_depth and len(friendids) > FRIENDS_OF_FRIENDS_LIMIT:\n",
    "                print 'Not all friends retrieved for %s.' % screen_name\n",
    "\n",
    "    except Exception, error:\n",
    "        print 'Error retrieving followers for user id: ', centre\n",
    "        print error\n",
    "\n",
    "        if os.path.exists(fname):\n",
    "            os.remove(fname)\n",
    "            print 'Removed file \"%s\".' % fname\n",
    "\n",
    "        sys.exit(1)\n",
    "\n",
    "    return taboo_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-s\", \"--screen-name\", required=True, help=\"Screen name of twitter user\")\n",
    "    ap.add_argument(\"-d\", \"--depth\", required=True, type=int, help=\"How far to follow user network\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    twitter_screenname = args['screen_name']\n",
    "    depth = int(args['depth'])\n",
    "\n",
    "    if depth < 1 or depth > 3:\n",
    "        print 'Depth value %d is not valid. Valid range is 1-3.' % depth\n",
    "        sys.exit('Invalid depth argument.')\n",
    "\n",
    "    print 'Max Depth: %d' % depth\n",
    "    matches = api.lookup_users(screen_names=[twitter_screenname])\n",
    "\n",
    "    if len(matches) == 1:\n",
    "        print get_follower_ids(matches[0].id, max_depth=depth)\n",
    "    else:\n",
    "        print 'Sorry, could not find twitter user with screen name: %s' % twitter_screenname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Sources\n",
    "\n",
    "[https://stackoverflow.com/questions/6399978/getting-started-with-twitter-oauth2-python](Getting started with Twitter\\OAuth2\\Python)\n",
    "\n",
    "[http://www.techpoweredmath.com/constructing-social-graph-twitter-plotly/#.WWuUx9MrKYW](Constructing a Social Graph With Twitter and Plotly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
